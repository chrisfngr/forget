import os
import json
import glob
import subprocess
from pathlib import Path
from datasets import load_dataset
from PIL import Image
import shutil

# æ•°æ®é›†åç§°
dataset_name = "zhhxte/mllm_cl_textvqa"

# æ ¹æ®æ•°æ®é›†åç§°åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå°† / æ›¿æ¢ä¸º _ï¼‰
dataset_folder_name = dataset_name.replace("/", "_")
data_dir = Path("data") / dataset_folder_name

# æ¸…ç†æ—§çš„æœªæŒ‰ repo ç»„ç»‡çš„æ•°æ®ï¼ˆé¿å…é‡å¤ï¼‰
old_data_dir = Path("data")
old_images_dir = old_data_dir / "images"
old_json_file = old_data_dir / "dataset.json"

if old_images_dir.exists() and old_images_dir.is_dir():
    print(f"ğŸ—‘ï¸  æ¸…ç†æ—§æ•°æ®: {old_images_dir}")
    shutil.rmtree(old_images_dir)
    print(f"   âœ“ å·²åˆ é™¤æ—§ images ç›®å½•")

if old_json_file.exists():
    print(f"ğŸ—‘ï¸  æ¸…ç†æ—§ JSON æ–‡ä»¶: {old_json_file}")
    old_json_file.unlink()
    print(f"   âœ“ å·²åˆ é™¤æ—§ dataset.json")

data_dir.mkdir(parents=True, exist_ok=True)
images_dir = data_dir / "images"
images_dir.mkdir(exist_ok=True)

# ç™»å½•ä½¿ç”¨ e.g. `huggingface-cli login` æ¥è®¿é—®è¿™ä¸ªæ•°æ®é›†
print("æ­£åœ¨åŠ è½½æ•°æ®é›†...")
print(f"æ•°æ®é›†: {dataset_name}")
print(f"å­˜å‚¨è·¯å¾„: {data_dir}")

# å½»åº•æ¸…ç†æ—§çš„ç¼“å­˜æ•°æ®ï¼ˆè§£å†³ 'List' ç±»å‹ä¸å…¼å®¹é—®é¢˜ï¼‰
print("ğŸ—‘ï¸  æ¸…ç† HuggingFace ç¼“å­˜...")
cache_base = Path.home() / ".cache" / "huggingface" / "datasets"
dataset_key = dataset_name.split("/")[-1]  # mllm_cl_clevr
if cache_base.exists():
    # ä½¿ç”¨ shell å‘½ä»¤å½»åº•æ¸…ç†
    subprocess.run(
        f"find {cache_base} -type d -name '*{dataset_key}*' -exec rm -rf {{}} + 2>/dev/null || true",
        shell=True,
        capture_output=True
    )
    print("   âœ“ ç¼“å­˜å·²æ¸…ç†")

# åŠ è½½æ•°æ®é›†ï¼ˆå¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼‰
print("æ­£åœ¨ä¸‹è½½æ•°æ®é›†...")
ds = load_dataset(dataset_name, download_mode="force_redownload")

print(f"æ•°æ®é›†ç»“æ„: {ds}")
print(f"æ•°æ®é›†åˆ†å‰²: {list(ds.keys())}")

# æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç»“æ„
if len(ds) > 0:
    first_split = list(ds.keys())[0]
    print(f"\næŸ¥çœ‹ {first_split} åˆ†å‰²çš„ç¬¬ä¸€ä¸ªæ ·æœ¬:")
    first_sample = ds[first_split][0]
    print(f"å­—æ®µ: {list(first_sample.keys())}")
    print(f"æ ·æœ¬å†…å®¹: {first_sample}")

# æŒ‰ç…§ HuggingFace æ•°æ®é›†ä¸­çš„ split æ¥ç»„ç»‡æ•°æ®
# ä¸ºæ¯ä¸ª split åˆ›å»ºå¯¹åº”çš„æ–‡ä»¶å¤¹å’Œ JSON æ–‡ä»¶
split_data = {}  # å­˜å‚¨æ¯ä¸ª split çš„æ•°æ®

for split_name, dataset in ds.items():
    print(f"\nå¤„ç†åˆ†å‰²: {split_name}, æ ·æœ¬æ•°: {len(dataset)}")
    
    # ä¸ºæ¯ä¸ª split åˆ›å»ºå¯¹åº”çš„å›¾åƒæ–‡ä»¶å¤¹
    split_images_dir = images_dir / split_name
    split_images_dir.mkdir(exist_ok=True)
    
    split_data[split_name] = []
    
    for idx, sample in enumerate(dataset):
        # åˆ›å»ºæ¯ä¸ªæ ·æœ¬çš„æ–‡ä»¶å¤¹ï¼ˆåœ¨å¯¹åº”çš„ split æ–‡ä»¶å¤¹ä¸‹ï¼‰
        sample_dir = split_images_dir / f"{idx:06d}"
        sample_dir.mkdir(exist_ok=True)
        
        # æå–å­—æ®µï¼ˆæ ¹æ®å®é™…æ•°æ®é›†ç»“æ„è°ƒæ•´ï¼‰
        # å‡è®¾å­—æ®µåä¸º problem, answer, image ç­‰ï¼Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        problem = sample.get("problem", sample.get("instruction", sample.get("question", "")))
        answer = sample.get("answer", sample.get("output", sample.get("response", "")))
        
        # å¤„ç†å›¾åƒ
        image_paths = []
        if "image" in sample:
            image = sample["image"]
            if isinstance(image, Image.Image):
                # è½¬æ¢ä¸º RGB æ¨¡å¼ï¼ˆå¦‚æœæ˜¯ RGBA æˆ–å…¶ä»–æ¨¡å¼ï¼‰
                if image.mode in ("RGBA", "LA", "P"):
                    # åˆ›å»ºç™½è‰²èƒŒæ™¯
                    rgb_image = Image.new("RGB", image.size, (255, 255, 255))
                    if image.mode == "P":
                        image = image.convert("RGBA")
                    rgb_image.paste(image, mask=image.split()[-1] if image.mode in ("RGBA", "LA") else None)
                    image = rgb_image
                elif image.mode != "RGB":
                    image = image.convert("RGB")
                
                # ä¿å­˜å›¾åƒ
                image_filename = f"image_0.jpg"
                image_path = sample_dir / image_filename
                image.save(image_path, "JPEG")
                # ä½¿ç”¨å®Œæ•´çš„ç»å¯¹è·¯å¾„
                absolute_path = str(image_path.resolve())
                image_paths.append(absolute_path)
        elif "images" in sample:
            # å¦‚æœæœ‰å¤šä¸ªå›¾åƒ
            images = sample["images"]
            if isinstance(images, list):
                for img_idx, img in enumerate(images):
                    if isinstance(img, Image.Image):
                        # è½¬æ¢ä¸º RGB æ¨¡å¼
                        if img.mode in ("RGBA", "LA", "P"):
                            rgb_image = Image.new("RGB", img.size, (255, 255, 255))
                            if img.mode == "P":
                                img = img.convert("RGBA")
                            rgb_image.paste(img, mask=img.split()[-1] if img.mode in ("RGBA", "LA") else None)
                            img = rgb_image
                        elif img.mode != "RGB":
                            img = img.convert("RGB")
                        
                        image_filename = f"image_{img_idx}.jpg"
                        image_path = sample_dir / image_filename
                        img.save(image_path, "JPEG")
                        # ä½¿ç”¨å®Œæ•´çš„ç»å¯¹è·¯å¾„
                        absolute_path = str(image_path.resolve())
                        image_paths.append(absolute_path)
        
        # æ„å»ºç¬¦åˆ LLaMA-Factory Alpaca æ ¼å¼çš„æ•°æ®
        data_item = {
            "instruction": problem,
            "input": "",  # ä¸å¡«ï¼ˆé€‰å¡«ï¼‰
            "output": answer,
            "images": image_paths
        }
        
        split_data[split_name].append(data_item)
        
        if (idx + 1) % 100 == 0:
            print(f"  å·²å¤„ç† {idx + 1}/{len(dataset)} ä¸ªæ ·æœ¬")

# æŒ‰ç…§ split ä¿å­˜æ•°æ®ï¼ˆä½¿ç”¨ HuggingFace æ•°æ®é›†ä¸­çš„åŸå§‹ splitï¼‰
print(f"\næŒ‰ç…§ HuggingFace æ•°æ®é›†ä¸­çš„ split ä¿å­˜æ•°æ®...")
total_samples = 0
saved_files = []

# å®šä¹‰ split åç§°æ˜ å°„ï¼štrain -> cl_train, test -> cl_test
split_name_mapping = {
    "train": "cl_train",
    "test": "cl_test"
}

for split_name, data_list in split_data.items():
    total_samples += len(data_list)
    
    # ä½¿ç”¨æ˜ å°„åçš„æ–‡ä»¶åï¼Œå¦‚æœæ²¡æœ‰æ˜ å°„åˆ™ä½¿ç”¨åŸå§‹åç§°
    file_name = split_name_mapping.get(split_name, split_name)
    split_file = data_dir / f"{file_name}.json"
    print(f"ä¿å­˜ {split_name} split åˆ° {split_file} ({len(data_list)} ä¸ªæ ·æœ¬)...")
    with open(split_file, "w", encoding="utf-8") as f:
        json.dump(data_list, f, ensure_ascii=False, indent=2)
    
    saved_files.append((split_name, split_file, len(data_list)))

print(f"\nå®Œæˆï¼")
print(f"- æ•°æ®é›†: {dataset_name}")
print(f"- æ€»æ ·æœ¬æ•°: {total_samples}")
print(f"- æ•°æ®é›†æ–‡ä»¶å¤¹: {data_dir}")
print(f"- å›¾åƒç›®å½•: {images_dir}")
print(f"\nä¿å­˜çš„æ–‡ä»¶:")
for split_name, split_file, count in saved_files:
    print(f"  - {split_name}: {split_file} ({count} ä¸ªæ ·æœ¬)")
